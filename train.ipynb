{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to train and use model for contact map predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements from requirements.txt before running notebook and install BLAST by running this command\n",
    "\n",
    "`apt install ncbi-blast+`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create `fasta` file from which you can create local BLAST database you can run this code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "from Bio.PDB import PDBParser\n",
    "from dataset.utils import residues_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fastas(id, seq, fasta_file):\n",
    "    name = re.sub('[^a-zA-Z0-9]', '_', id)\n",
    "\n",
    "    with open(fasta_file, 'a') as f:\n",
    "        f.write(f\"> {name} \\n\")\n",
    "        f.write(seq)\n",
    "        f.write('\\n\\n')\n",
    "\n",
    "parser = PDBParser()\n",
    "pdb_files_folder = \"path\"\n",
    "fasta_file = \"database.fasta\"\n",
    "all_pdbs = glob.glob(pdb_files_folder)\n",
    "for i, pdb in tqdm.tqdm(enumerate(all_pdbs)):\n",
    "    structure = parser.get_structure(os.path.basename(os.path.splitext(pdb)[0]), pdb)\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            protein_sequence = \"\"\n",
    "            residues = []\n",
    "            for residue in chain:\n",
    "                if residue.id[0] == ' ':\n",
    "                    protein_sequence += residues_id_map.get(residue.get_resname(), \"X\")\n",
    "                    residues.append(residue)\n",
    "            build_fastas(structure.id + \"_\" + str(model.id) + \"_\" + chain.id, protein_sequence, fasta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create database just run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast.Applications import NcbimakeblastdbCommandline\n",
    "\n",
    "fasta_file = \"database.fasta\"\n",
    "db_name = \"database_name\"\n",
    "\n",
    "makeblastdb_cline = NcbimakeblastdbCommandline(input_file=fasta_file, dbtype=\"prot\", out=db_name)\n",
    "stdout, stderr = makeblastdb_cline()\n",
    "\n",
    "print(\"Database created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently we are just removing this warnings to not mess up outputs by them, but in future they should be fixed\n",
    "import warnings\n",
    "from Bio import BiopythonParserWarning\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BiopythonParserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=PDBConstructionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ContactMapPredictor\n",
    "from dataset import PDBDataModule\n",
    "from lightning_module import ContactMapLightningModule\n",
    "\n",
    "import esm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "train_dir = \"../train\"  # Directory with training PDB files\n",
    "test_dir = \"../test\"    # Directory with test PDB files\n",
    "batch_size = 1\n",
    "num_workers = 0\n",
    "\n",
    "esm_model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "esm_model = esm_model.to(device)\n",
    "\n",
    "data_module = PDBDataModule(train_dir, test_dir, esm_model, batch_converter, device,\n",
    "                            database_folder=train_dir, db_name=\"train_db\", e_value_threshold=1e-3, k=5,\n",
    "                            val_split=0.2, batch_size=batch_size, num_workers=num_workers, max_sequence_length=100)\n",
    "data_module.setup()\n",
    "\n",
    "model = ContactMapPredictor(embeddings_size=320, fusion_num_blocks=10)\n",
    "lightning_module = ContactMapLightningModule(model=model, learning_rate=1e-3)\n",
    "lightning_module.to(device)\n",
    "\n",
    "logger = TensorBoardLogger(\"logs\", name=\"contact_map_experiment\")\n",
    "trainer = pl.Trainer(max_epochs=10, logger=logger)\n",
    "\n",
    "trainer.fit(lightning_module, data_module.train_dataloader(), data_module.val_dataloader())\n",
    "\n",
    "trainer.test(lightning_module, dataloaders=data_module.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
